<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="牛顿法 梯度下降法"><meta name="keywords" content=""><meta name="author" content="Charon Cheung"><meta name="copyright" content="Charon Cheung"><title>牛顿法 梯度下降法 | 沉默杀手</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.6.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.6.1"><link rel="dns-prefetch" href="https://cdn.staticfile.org"><link rel="dns-prefetch" href="https://cdn.bootcss.com"><link rel="dns-prefetch" href="https://creativecommons.org"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script><meta name="generator" content="Hexo 5.4.0"></head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="toggle-sidebar-info text-center"><span data-toggle="Toggle article">Toggle site</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98"><span class="toc-number">1.</span> <span class="toc-text">非线性最小二乘</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9D%9E%E7%BA%BF%E6%80%A7%E4%BC%98%E5%8C%96%E4%B8%AD%E7%9A%84%E7%89%9B%E9%A1%BF%E6%B3%95"><span class="toc-number">2.</span> <span class="toc-text">非线性优化中的牛顿法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95"><span class="toc-number">3.</span> <span class="toc-text">梯度下降法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90%E4%B8%AD%E7%9A%84%E7%89%9B%E9%A1%BF%E6%B3%95"><span class="toc-number">4.</span> <span class="toc-text">数值分析中的牛顿法</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="https://s2.loli.net/2022/02/17/HQaCXUBn64zsMIL.png"></div><div class="author-info__name text-center">Charon Cheung</div><div class="author-info__description text-center"></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">666</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">6</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">53</span></a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://s2.loli.net/2022/11/17/QOR8cePIS5NdDrK.jpg)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">沉默杀手</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus"><a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span></div><div id="post-info"><div id="post-title">牛顿法 梯度下降法</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2021-07-13</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E7%AE%97%E6%B3%95%E6%8E%A8%E5%AF%BC/">算法推导</a><span class="post-meta__separator">|</span><i class="fa fa-comment-o post-meta__icon" aria-hidden="true"></i><a href="/2021/07/13/%E7%AE%97%E6%B3%95%E6%8E%A8%E5%AF%BC/%E7%89%9B%E9%A1%BF%E6%B3%95%20%20%E6%9C%80%E9%80%9F%E4%B8%8B%E9%99%8D%E6%B3%95/#disqus_thread"><span class="disqus-comment-count" data-disqus-identifier="2021/07/13/算法推导/牛顿法  最速下降法/"></span></a><div class="post-meta-wordcount"><span>Word count: </span><span class="word-count">1.6k</span><span class="post-meta__separator">|</span><span>Reading time: 5 min</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><h2 id="非线性最小二乘"><a href="#非线性最小二乘" class="headerlink" title="非线性最小二乘"></a>非线性最小二乘</h2><p>非线性优化问题就是针对一个非线性函数求最值的问题，但很难通过求导数的方式求解。<br>非线性最小二乘问题的形式如下：</p>
<script type="math/tex; mode=display">\min_{x} \frac{1}{2} {\mid \mid f(x) \mid \mid}^2_{2}</script><p>自变量 <script type="math/tex">x\in R^n</script>，f 是任意的非线性函数，我们可以假设它有m维： <script type="math/tex">f(x)\in R^m</script></p>
<p>我们一般用李代数表示机器人的平移和旋转，常常无法对f进行直接求导，所以使用迭代的方式求解，非线性优化的几个解法都是使用迭代</p>
<ol>
<li>给定某个初始值<script type="math/tex">x_0</script></li>
<li>对于第k次迭代，寻找一个增量<script type="math/tex">\Delta{x_k}</script>， 使得 <script type="math/tex">{\mid \mid f(x)+\Delta{x_k} \mid \mid}^2_{2}</script> 达到极小值</li>
<li>若<script type="math/tex">\Delta{x_k}</script>足够小，则停止</li>
<li>否则，令 <script type="math/tex">{x_{k+1}} = x_k + \Delta{x_k}</script> ， 返回第2步</li>
</ol>
<p>非线性最小二乘问题就转为寻找 <script type="math/tex">\Delta{x_k}</script> 的问题，直到<strong>满足迭代次数或者目标函数变化非常小</strong>为止。此时认为算法收敛，目标函数达到极小值。</p>
<h2 id="非线性优化中的牛顿法"><a href="#非线性优化中的牛顿法" class="headerlink" title="非线性优化中的牛顿法"></a>非线性优化中的牛顿法</h2><p>普通的函数求极值就是对f’(x)=0进行求解，但是有时导数难以获得，所以把f(x)进行二阶泰勒展开</p>
<script type="math/tex; mode=display">f(x+\Delta x) \approx f(x) + f'(x)\Delta x + \frac{1}{2}f''(x)\Delta x^2</script><p>右侧对 <script type="math/tex">\Delta x</script> 求导并令其为0，可以获得</p>
<script type="math/tex; mode=display">\Delta x = - \frac{f'(x)}{f''(x)}</script><p>也就是<script type="math/tex">x_{n+1}= x_{n}- \frac{f'(x)}{f''(x)}</script></p>
<p>现在放到高维情况下，把最开始的式子在x附近二阶泰勒展开:</p>
<script type="math/tex; mode=display">\left\|f(x+\Delta x)\right\|_2^2 \approx \left\|f(x)\right\|_2^2 + J(x)\Delta x + \frac{1}{2}\Delta x^TH\Delta x</script><p>变量的增量就可以获得:  <script type="math/tex">H\Delta x = -J^T</script></p>
<p>J是关于x的一阶导数，雅克比矩阵；H是二阶导数，海森矩阵。</p>
<p>牛顿法的思路是将函数 f 在 x 处展开为多元二次函数，再通过求解二次函数最小值的方法得到本次迭代的下降方向。那么问题来了，多元二次函数在梯度为0的地方一定存在最小值么？直觉告诉我们是不一定的。以一元二次函数 g(x)=ax<sup>2</sup>+bx+c为例，我们知道当a&gt;0时，g(x)可以取得最小值，否则g(x)不存在最小值。</p>
<p>推广到多元的情况，可以得出<strong>二次项矩阵(Hessian矩阵)必须是正定的，函数f(x)的最小值才存在</strong>。因此，<font color = blue size=4> 牛顿法首先需要计算海森矩阵并且判断其正定性，这在问题规模很大时非常困难</font>，我们希望避免计算海森矩阵。</p>
<p><br><br><strong>牛顿法的特点</strong>：</p>
<ul>
<li>在极小值点附近，牛顿法的收敛速度比梯度下降法 快很多</li>
<li>需要计算海森矩阵，但问题规模大时，计算难度很大</li>
<li>牛顿法经常会因为海森矩阵不正定而发散，因此牛顿法并不是非常的稳定</li>
</ul>
<h2 id="梯度下降法"><a href="#梯度下降法" class="headerlink" title="梯度下降法"></a>梯度下降法</h2><p>对上面公式(1)进行展开时，如果只保留一阶项，对应一阶梯度法，<script type="math/tex">f(x+\Delta x) = f(x)+J\Delta x</script></p>
<p>我们希望迭代过程中的函数值逐步减小，也就是<script type="math/tex">f(x+\Delta x) \le f(x)</script>。 可以让<script type="math/tex">\Delta x = -J^T(x)</script> 由于<script type="math/tex">JJ^T > 0</script>，所以实现了函数值下降</p>
<p>也就是沿着反向梯度的方向，还要取一个步长，这就是最速下降法。 <strong>特点:</strong> <font color = blue size=4>最速下降法过于贪心，越靠近极小值速度越慢，容易走出锯齿路线，反而增加迭代次数。 </font></p>
<p>牛顿法是二阶收敛，梯度下降是一阶收敛，所以牛顿法就更快。如果更通俗地说的话，比如你想找一条最短的路径走到一个盆地的最底部，梯度下降法每次只从你当前所处位置选一个坡度最大的方向走一步，牛顿法在选择方向时，不仅会考虑坡度是否够大，还会考虑你走了一步之后，坡度是否会变得更大。可以说牛顿法比梯度下降法看得更远一点，能更快地走到最底部。（牛顿法目光更加长远，所以少走弯路；相对而言，<font color = blue size=4>梯度下降法只考虑了局部的最优 </font>，没有全局思想。）</p>
<p>从几何上说，牛顿法就是用一个二次曲面去拟合你当前所处位置的局部曲面，而梯度下降法是用一个平面去拟合当前的局部曲面。通常情况下，二次曲面的拟合会比平面更好，所以牛顿法选择的下降路径会更符合真实的最优下降路径。</p>
<h2 id="数值分析中的牛顿法"><a href="#数值分析中的牛顿法" class="headerlink" title="数值分析中的牛顿法"></a>数值分析中的牛顿法</h2><p>牛顿迭代法最常见的一个应用就是求方根</p>
<p>牛顿法是一种在实数域和复数域上近似求解方程的方法。方法使用函数f(x)的泰勒级数的前面几项来寻找方程f(x) = 0的根。牛顿法最大的特点就在于它的收敛速度很快。</p>
<p>首先，选择一个<strong>接近函数f(x)零点的 x0</strong>，计算相应的f(x0) 和切线斜率f’(x0)。然后我们计算穿过点<code>(x0, f(x0) )</code>并且斜率为f’(x0)的直线和 x 轴的交点的x坐标，也就是求如下方程的解：<br>f’(x<sub>0</sub>)(x-x<sub>0</sub>) + f(x<sub>0</sub>) = 0</p>
<p>这样将新求得的点的x坐标命名为x<sub>1</sub>，通常x<sub>1</sub>会比x<sub>0</sub>更接近方程f(x) = 0的解。因此可以利用x<sub>1</sub>开始下一轮迭代，迭代公式如下所示:<br><img src="https://i.loli.net/2021/07/14/4cAgeqyZajVHzuC.png" alt=""></p>
<p>也就是知道曲线在某个点x<sub>0</sub>的切线l，用l和x轴的交点作为下一个迭代点x<sub>1</sub>，如此迭代来逼近曲线和x轴的交点。</p>
<p>已经证明，如果<code>f&#39;</code>是连续的，并且待求的零点x是孤立的，那么在零点x周围存在一个区域，只要初始值x<sub>0</sub>位于这个邻近区域内，那么牛顿法必定收敛。下图为一个牛顿法执行过程的例子<br><img src="https://i.loli.net/2021/07/14/9YurNHX1Ag3qajT.gif" alt=""></p>
<p>参考:<br><a target="_blank" rel="noopener" href="https://scm_mos.gitlab.io/algorithm/newton-and-gauss-newton/">牛顿法 高斯牛顿法</a><br><a target="_blank" rel="noopener" href="http://www.whudj.cn/?p=1042">梯度下降法(gradient descent)与牛顿法</a></p>
</div></article><div class="post-meta__tag-list"></div><nav id="pagination"><div class="prev-post pull-left"><a href="/2021/07/13/%E7%AE%97%E6%B3%95%E6%8E%A8%E5%AF%BC/%E9%AB%98%E6%96%AF%E7%89%9B%E9%A1%BF%E6%B3%95/"><i class="fa fa-chevron-left">  </i><span>高斯牛顿法</span></a></div><div class="next-post pull-right"><a href="/2021/07/11/%E6%BF%80%E5%85%89SLAM/Cartographer/%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/%E5%A4%84%E7%90%86%E5%AD%90%E5%9B%BE%202.%20%E7%90%86%E8%AE%BA%EF%BC%8Chit%E8%A1%A8%E5%92%8Cmiss%E8%A1%A8/"><span>处理子图 2. 理论，hit表和miss表</span><i class="fa fa-chevron-right"></i></a></div></nav><div id="disqus_thread"></div><script>var unused = null;
var disqus_config = function () {
  this.page.url = 'https://charon-cheung.github.io/2021/07/13/%E7%AE%97%E6%B3%95%E6%8E%A8%E5%AF%BC/%E7%89%9B%E9%A1%BF%E6%B3%95%20%20%E6%9C%80%E9%80%9F%E4%B8%8B%E9%99%8D%E6%B3%95/';
  this.page.identifier = '2021/07/13/算法推导/牛顿法  最速下降法/';
  this.page.title = '牛顿法 梯度下降法';
}
var d = document, s = d.createElement('script');
s.src = "https://" + '沉默杀手' +".disqus.com/embed.js";
s.setAttribute('data-timestamp', '' + +new Date());
(d.head || d.body).appendChild(s);</script><script id="dsq-count-scr" src="https://沉默杀手.disqus.com/count.js" async></script></div></div><footer class="footer-bg" style="background-image: url(https://s2.loli.net/2022/11/17/QOR8cePIS5NdDrK.jpg)"><div class="layout" id="footer"><div class="copyright">&copy;2018 - 2024 By Charon Cheung</div><div class="framework-info"><span>Driven - </span><a target="_blank" rel="noopener" href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a target="_blank" rel="noopener" href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file-o"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.6.1"></script><script src="/js/fancybox.js?version=1.6.1"></script><script src="/js/sidebar.js?version=1.6.1"></script><script src="/js/copy.js?version=1.6.1"></script><script src="/js/fireworks.js?version=1.6.1"></script><script src="/js/transition.js?version=1.6.1"></script><script src="/js/scroll.js?version=1.6.1"></script><script src="/js/head.js?version=1.6.1"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.bootcss.com/mathjax/2.7.2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script>if(/Android|webOS|iPhone|iPod|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
}</script></body></html>